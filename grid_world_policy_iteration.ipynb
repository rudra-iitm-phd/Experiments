{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ENV:\n",
    "      def __init__(self, size: tuple, terminal_states: list):\n",
    "            \n",
    "            self.grid = np.zeros(size)\n",
    "            self.terminal_states = terminal_states\n",
    "            self.actions = ['up', 'down', 'left', 'right']\n",
    "            self.agent_position = [3,0]\n",
    "\n",
    "      def make_move(self, state, action):\n",
    "            if state in self.terminal_states:\n",
    "                  return state\n",
    "            if action == 'left':\n",
    "                  self.agent_position = [state[0], max(0, state[1]-1)]\n",
    "                  return [state[0], max(0, state[1]-1)]\n",
    "            elif action == 'right':\n",
    "                  self.agent_position = [state[0], min(self.grid.shape[1]-1, state[1]+1)]\n",
    "                  return [state[0], min(self.grid.shape[1]-1, state[1]+1)]\n",
    "            elif action == 'up':\n",
    "                  self.agent_position = [max(state[0]-1, 0), state[1]]\n",
    "                  return [max(state[0]-1, 0), state[1]]\n",
    "            elif action == 'down':\n",
    "                  self.agent_position = [min(self.grid.shape[0]-1, state[0]+1), state[1]]\n",
    "                  return [min(self.grid.shape[0]-1, state[0]+1), state[1]]\n",
    "\n",
    "      def get_reward(self, state, action):\n",
    "            if state in self.terminal_states:\n",
    "                  return 0, state\n",
    "            new_state = self.make_move(state, action)\n",
    "            return -1, new_state\n",
    "\n",
    "      def display(self, agent = False):\n",
    "            for i in range(self.grid.shape[0]):\n",
    "                  temp = []\n",
    "                  for j in range(self.grid.shape[1]):\n",
    "                        \n",
    "                        if [i,j] in self.terminal_states:\n",
    "                              if agent and self.agent_position == [i,j]:\n",
    "                                    temp.append('X*')\n",
    "                              else:\n",
    "                                    temp.append('X')\n",
    "                              \n",
    "                        else :\n",
    "                              if agent and self.agent_position == [i,j]:\n",
    "                                    temp.append('*')\n",
    "                              else:\n",
    "                                    temp.append('-')\n",
    "                  print(' '.join(_ for _ in temp))\n",
    "            \n",
    "\n",
    "\n",
    "      \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ENV((4,4), [[0,0], [3,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X - - -\n",
      "- - - -\n",
      "- - - -\n",
      "* - - X\n"
     ]
    }
   ],
   "source": [
    "env.display(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.get_reward(env.agent_position, 'up')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy:\n",
    "      def __init__(self, env:ENV):\n",
    "            self.actions = ['up', 'down', 'left', 'right']\n",
    "            self.grid = env.grid\n",
    "            self.V = env.grid\n",
    "            self.terminal_states = env.terminal_states\n",
    "            self.policy = {i:{j:{a:0.25 for a in self.actions} if [i,j] not in self.terminal_states else {a: 0 for a in self.actions} for j in range(self.grid.shape[1])  } for i in range(self.grid.shape[0])}\n",
    "            self.env =  env\n",
    "\n",
    "      def evaluate_policy(self, eps = 1e-2):\n",
    "            delta = 0\n",
    "            old_V = self.V\n",
    "            err = 1e3\n",
    "            while err > eps:\n",
    "                  for i in range(self.grid.shape[0]):\n",
    "                        for j in range(self.grid.shape[1]):\n",
    "                              s_prime_reward = [self.env.get_reward([i,j], a) for a in self.env.actions]\n",
    "                              self.V[i,j] = sum(self.policy[i][j][a]*(r_p + self.V[s_p[0], s_p[1]]) for (a, (r_p, s_p)) in zip(self.env.actions, s_prime_reward))\n",
    "                  delta = max(delta, abs(old_V.sum() - self.V.sum()))\n",
    "                  err = delta\n",
    "                  print(abs(old_V.sum() - self.V.sum()))\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = Policy(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi.V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['up', 'down', 'left', 'right'])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi.policy[0][2].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "pi.evaluate_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.       , -1.       , -1.25     , -1.3125   ],\n",
       "       [-1.       , -1.5      , -1.6875   , -1.75     ],\n",
       "       [-1.25     , -1.6875   , -1.84375  , -1.8984375],\n",
       "       [-1.3125   , -1.75     , -1.8984375,  0.       ]])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi.V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9be210f112d3bd93a6327b459217e15105c4405a02aec2765b09f959417e942a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
